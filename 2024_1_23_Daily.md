# 2024年1月23日 日报

早上先看了下如何用api的方式访问部署在本地的qwen模型  

打算先拿1.8b的来代替gpt做尝试，如果1.8b能成功的话，就可以无缝切换到72b了

然后看了下发现qwen的api结构基本上就是照着openai api key的结构进行设计的，也就是说不需要对项目所有openai的部分进行大改，大部分的openai内容都可以保留，这样工作量就会小不少，而且正好mt-bench是以gpt-4为judge模型的，所以正好可以替换起来  

下面是总结好的命令行启动项代码

```python
'''
下面是命令行指令
获取模型答案
python gen_model_answer.py --model-path /home/featurize/Qwen-1_8B-Chat --model-id Qwen-1_8B-Chat
生成打分
python gen_judgment.py --model-list Qwen-1_8B-Chat
汇总打分
python show_result.py
'''
```

然后完整的代码可以查看[FastChat/fastchat/llm_judge at qwen · qzy03715/FastChat (github.com)](https://github.com/qzy03715/FastChat/tree/qwen/fastchat/llm_judge)

- 遇到的一个问题：需要创建两个虚拟环境
  - qwen的用pydantic 2.1.1 
    `pip uninstall pydantic`  
  - `pip install pydantic 2.1.1`  
  - fastchat要用pydantic<2.0.0的  
    `pip install fastapi uvicorn pydantic==2.1.1 openai sse_starlette`  

替换完以后，使用qwen1.8生成答案，然后再使用qwen1.8进行打分，总共80道题都可以出分，不会出现用gpt3.5那种跑一半报错的情况

目前来看qwen1.8作为打分模型效果一般般，比如说规定打1-10分给我打了很多个-1，而且qwen1.8似乎也没办法理解数学内容
