# 2024年1月3日 日报

首先将[LLaMA-Factory](https://github.com/qzy03715/LLaMA-Factory)里面关于[模型评估](https://github.com/qzy03715/LLaMA-Factory/blob/main/README_zh.md#%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0)的部分成功跑通了

测试了两个模型，一个是GLM3一个是千义通问1.8b

代码流程在[这边](https://www.yuque.com/chougoushi0v0/kb/ps3va8puw4lxwlz0?singleDoc)查看

目前遇到的问题一个是只能得知测评的结果也就是四个方面的分数，而测评的数据集，测评的具体框架，具体方法还不清楚

开完会以后先把工作流程从notepad++换成用vscode远程连接服务器，这样方便后续对代码打断点进行调试

明天的工作内容是对[LLaMA-Factory](https://github.com/qzy03715/LLaMA-Factory)当中的[evaluator.py](https://github.com/qzy03715/LLaMA-Factory/blob/main/src/llmtuner/eval/evaluator.py)进行调试

需要了解的内容：

- 测评用的数据集具体是什么，形式是什么样的，是否可以替换成我们自己的
- 测试用的具体方法是什么，是主观题对比相似性，还是客观题什么的
- 得分是如何计算的，如何把主观题，客观题的回答情况抽象成一个数字的
